#   min_n = tune()) %>% # tune minimum number of data points in a node
#   set_engine(engine = engine, importance = "impurity") %>% #engine-specific arguments
#   set_mode(mode = mode)
model <- goophi::randomForest_phi(trees = tune(), ## tune 넘길 때 null로 전달되는 문제
min_n = tune(),
mtry = tune(),
engine = engine,
mode = mode)
model
engine = "kknn"
mode = "classification"
model2 <- goophi::knn_phi(k = "2",
engine = engine,
mode = mode)
model2
?vfold_cv
## set workflow
tune_wf <- workflow() %>%
add_recipe(rec) %>%
add_model(model)
## v-fold cv
folds <- vfold_cv(data_train, v = 2)
folds
## v-fold cv
folds <- vfold_cv(data_train, v = 1)
2
## v-fold cv
folds <- vfold_cv(data_train, v = 2)
## v-fold cv
folds <- vfold_cv(data_train, v = 1)
?parsnip::rand_forest
?add_recipe
## set workflow
tune_wf <- workflows::workflow() %>%
workflows::add_recipe(rec) %>%
workflows::add_model(model)
?vfold_cv
## v-fold cv
folds <- rsample::vfold_cv(data_train, v = 2)
?parsnip::nearest_neighbor
?parsnip::logistic_reg()
library(goophi)
library(tidymodels)
library(dplyr)
library(recipes)
library(parsnip)
library(tune)
library(rsample)
library(vip)
library(goophi)
set.seed(1234)
## data import
data(titanic_train, package = "titanic")
cleaned_data <- tibble::as_tibble(titanic_train) %>%
select(-c(PassengerId, Name, Cabin, Ticket)) %>%
mutate(across(where(is.character), factor)) %>%
mutate(Survived = as.factor(Survived ))
## one-hot encoding
rec <- recipe(Survived ~ ., data = cleaned_data) %>%
step_dummy(all_predictors(), -all_numeric())
rec_prep <- prep(rec)
cleaned_data <- bake(rec_prep, new_data = cleaned_data)
## 여기까지 완료된 데이터가 전달된다고 가정 (one-hot encoding까지 되는지 확인 필요) ##
## 아래부터 ####으로 구분된 파트를 묶어 함수화할 예정 ##
#### train-test split ####
targetVar <- "Survived"
data_train <- goophi::trainTestSplit(data = cleaned_data, target = targetVar)[[1]]
data_test <- goophi::trainTestSplit(data = cleaned_data, target = targetVar)[[2]]
data_split<-goophi::trainTestSplit(data = cleaned_data, target = targetVar)[[3]]
#### make recipe for CV ####
# pca_thres <- "0.7"
# f <- "Survived~."
#
# rec <- recipe(eval(parse(text = f)), data = data_train) %>%
#   step_impute_knn(all_predictors()) %>% ## imputation
#   step_center(all_predictors())  %>%
#   step_scale(all_predictors()) %>% ## standardization or scaling
#   step_pca(all_predictors(), threshold = eval(parse(text = pca_thres))) ## PCA for numeric var only or all predictors
imputation <- TRUE
scaling <- TRUE
pca <- TRUE
formula <- "Survived ~ ."
pca_thres <- "0.7"
rec <- goophi::preprocessing(data = data_train,
formula,
imputationType = "mean",
normalizationType = "range", # min-max normalization as default
pca_thres = pca_thres,
imputation = TRUE,
normalization = TRUE,
pca = TRUE)
#### modeling ####
engine = "ranger"
mode = "classification"
# model <- parsnip::rand_forest(
#   mtry = tune(), # tune number of sampled predictors at each split
#   trees = tune(), # tune number of trees
#   min_n = tune()) %>% # tune minimum number of data points in a node
#   set_engine(engine = engine, importance = "impurity") %>% #engine-specific arguments
#   set_mode(mode = mode)
model <- goophi::randomForest_phi(trees = tune(), ## tune 넘길 때 null로 전달되는 문제
min_n = tune(),
mtry = tune(),
engine = engine,
mode = mode)
model
parameter_grid <- dials::grid_regular(
min_n(range = c(10, 40)),
mtry(range = c(1, 5)),
trees(range = c(500, 2000)),
levels = 5)
v <- 2
# ## set workflow
tune_rf <- workflows::workflow() %>%
workflows::add_recipe(rec) %>%
workflows::add_model(model)
## v-fold cv
folds <- rsample::vfold_cv(data_train, v = 2)
## grid search CV
regular_res <- tune_grid(tune_rf, resamples = folds, grid = parameter_grid) # warnings
regular_res <- goophi::gridSerachCV(rec = rec,
model = model,
v = v,
data = data_train,
parameter_grid = parameter_grid
)[2]
regular_res
## results of grid search CV
regular_res %>% collect_metrics()
autoplot(regular_res)
regular_res <- goophi::gridSerachCV(rec = rec,
model = model,
v = v,
data = data_train,
parameter_grid = parameter_grid
)
regular_res
regular_res[1]
regular_res[2]
regular_res[[1]]
regular_res[[2]]
regular_res[[1]]
## results of grid search CV
regular_res[[1]] %>% collect_metrics()
## results of grid search CV
regular_res[[2]] %>% collect_metrics()
autoplot(regular_res[[2]])
#### finalize model ####
show_best_params <- show_best(regular_res[[2]], n = 1, metric = "roc_auc") # regular_res$.metrics
Best_params <- tune::select_best(regular_res[[2]], metric = "roc_auc") ## metric 목록 print 되도록
final_spec <- tune::finalize_model(model, Best_params)
final_model <- final_spec %>% fit(eval(parse(text = formula)), data_train)
# last_fitted_model
last_fitted_model <-
tune_wf %>%
update_model(final_spec) %>%
last_fit(data_split)
# last_fitted_model
last_fitted_model <-
regular_res[[1]] %>%
update_model(final_spec) %>%
last_fit(data_split)
regular_res[[2]]
# performance of final model
last_fitted_model %>% collect_metrics()
# importance
last_fitted_model %>%
extract_fit_parsnip() %>%
vip(num_features = 5)
# importance
last_fitted_model %>%
extract_fit_parsnip() %>%
vip()
# ROC Curve
last_fitted_model %>%
collect_predictions() %>%
#mutate(Survived = as.numeric(Survived)) %>%
#mutate(.pred_class = as.numeric(.pred_class)) %>%
roc_curve(Survived, .pred_class) %>%
autoplot()
library(tidymodels)
library(dplyr)
library(recipes)
library(parsnip)
library(tune)
library(rsample)
library(vip)
library(goophi)
set.seed(1234)
## data import
data(titanic_train, package = "titanic")
cleaned_data <- tibble::as_tibble(titanic_train) %>%
select(-c(PassengerId, Name, Cabin, Ticket)) %>%
mutate(across(where(is.character), factor)) %>%
mutate(Survived = as.factor(Survived ))
## one-hot encoding
rec <- recipe(Survived ~ ., data = cleaned_data) %>%
step_dummy(all_predictors(), -all_numeric())
rec_prep <- prep(rec)
cleaned_data <- bake(rec_prep, new_data = cleaned_data)
## 여기까지 완료된 데이터가 전달된다고 가정 (one-hot encoding까지 되는지 확인 필요) ##
## 아래부터 ####으로 구분된 파트를 묶어 함수화할 예정 ##
#### train-test split ####
targetVar <- "Survived"
data_train <- goophi::trainTestSplit(data = cleaned_data, target = targetVar)[[1]]
data_test <- goophi::trainTestSplit(data = cleaned_data, target = targetVar)[[2]]
data_split<-goophi::trainTestSplit(data = cleaned_data, target = targetVar)[[3]]
#### make recipe for CV ####
# pca_thres <- "0.7"
# f <- "Survived~."
#
# rec <- recipe(eval(parse(text = f)), data = data_train) %>%
#   step_impute_knn(all_predictors()) %>% ## imputation
#   step_center(all_predictors())  %>%
#   step_scale(all_predictors()) %>% ## standardization or scaling
#   step_pca(all_predictors(), threshold = eval(parse(text = pca_thres))) ## PCA for numeric var only or all predictors
imputation <- TRUE
scaling <- TRUE
pca <- FALSE
formula <- "Survived ~ ."
pca_thres <- "0.7"
rec <- goophi::preprocessing(data = data_train,
formula,
imputationType = "mean",
normalizationType = "range", # min-max normalization as default
pca_thres = pca_thres,
imputation = TRUE,
normalization = TRUE,
pca = TRUE)
#### modeling ####
engine = "ranger"
mode = "classification"
# model <- parsnip::rand_forest(
#   mtry = tune(), # tune number of sampled predictors at each split
#   trees = tune(), # tune number of trees
#   min_n = tune()) %>% # tune minimum number of data points in a node
#   set_engine(engine = engine, importance = "impurity") %>% #engine-specific arguments
#   set_mode(mode = mode)
model <- goophi::randomForest_phi(trees = tune(), ## tune 넘길 때 null로 전달되는 문제
min_n = tune(),
mtry = tune(),
engine = engine,
mode = mode)
model
# engine = "kknn"
# mode = "classification"
#
# model2 <- goophi::knn_phi(k = tune(),
#                           engine = engine,
#                           mode = mode)
#
# model2
# model2 <- nearest_neighbor() %>%
#   set_engine("kknn") %>%
#   set_mode("classification")
#
# knn_fit <- model2 %>%
#   fit(eval(parse(text = formula)), data = data_train)
#
# knn_fit %>%
#   predict(data_test)
#### Grid serach CV ####
# model 1 : RF
# set parameter_grid / need to set default range
parameter_grid <- dials::grid_regular(
min_n(range = c(10, 40)),
mtry(range = c(1, 5)),
trees(range = c(500, 2000)),
levels = 5)
v <- 2
# ## set workflow
tune_rf <- workflows::workflow() %>%
workflows::add_recipe(rec) %>%
workflows::add_model(model)
## v-fold cv
folds <- rsample::vfold_cv(data_train, v = 2)
regular_res <- goophi::gridSerachCV(rec = rec,
model = model,
v = v,
data = data_train,
parameter_grid = parameter_grid
)
imputation <- TRUE
normalization <- TRUE
pca <- FALSE
formula <- "Survived ~ ."
pca_thres <- "0.7"
rec <- goophi::preprocessing(data = data_train,
formula,
imputationType = "mean",
normalizationType = "range", # min-max normalization as default
pca_thres = pca_thres,
imputation = imputation,
normalization = normalization,
pca = pca)
engine = "ranger"
mode = "classification"
# model <- parsnip::rand_forest(
#   mtry = tune(), # tune number of sampled predictors at each split
#   trees = tune(), # tune number of trees
#   min_n = tune()) %>% # tune minimum number of data points in a node
#   set_engine(engine = engine, importance = "impurity") %>% #engine-specific arguments
#   set_mode(mode = mode)
model <- goophi::randomForest_phi(trees = tune(), ## tune 넘길 때 null로 전달되는 문제
min_n = tune(),
mtry = tune(),
engine = engine,
mode = mode)
model
# engine = "kknn"
# mode = "classification"
#
# model2 <- goophi::knn_phi(k = tune(),
#                           engine = engine,
#                           mode = mode)
#
# model2
# model2 <- nearest_neighbor() %>%
#   set_engine("kknn") %>%
#   set_mode("classification")
#
# knn_fit <- model2 %>%
#   fit(eval(parse(text = formula)), data = data_train)
#
# knn_fit %>%
#   predict(data_test)
#### Grid serach CV ####
# model 1 : RF
# set parameter_grid / need to set default range
parameter_grid <- dials::grid_regular(
min_n(range = c(10, 40)),
mtry(range = c(1, 5)),
trees(range = c(500, 2000)),
levels = 5)
v <- 2
# ## set workflow
tune_rf <- workflows::workflow() %>%
workflows::add_recipe(rec) %>%
workflows::add_model(model)
## v-fold cv
folds <- rsample::vfold_cv(data_train, v = 2)
regular_res <- goophi::gridSerachCV(rec = rec,
model = model,
v = v,
data = data_train,
parameter_grid = parameter_grid
)
## results of grid search CV
regular_res[[2]] %>% collect_metrics()
autoplot(regular_res[[2]])
#### finalize model ####
show_best_params <- show_best(regular_res[[2]], n = 1, metric = "roc_auc") # regular_res$.metrics
Best_params <- tune::select_best(regular_res[[2]], metric = "roc_auc") ## metric 목록 print 되도록
final_spec <- tune::finalize_model(model, Best_params)
final_model <- final_spec %>% fit(eval(parse(text = formula)), data_train)
# last_fitted_model
last_fitted_model <-
regular_res[[1]] %>%
update_model(final_spec) %>%
last_fit(data_split)
# performance of final model
last_fitted_model %>% collect_metrics()
# importance
last_fitted_model %>%
extract_fit_parsnip() %>%
vip()
# ROC Curve
last_fitted_model %>%
collect_predictions() %>%
#mutate(Survived = as.numeric(Survived)) %>%
#mutate(.pred_class = as.numeric(.pred_class)) %>%
roc_curve(Survived, .pred_class) %>%
autoplot()
# ROC Curve
last_fitted_model %>%
collect_predictions() %>%
#mutate(Survived = as.numeric(Survived)) %>%
#mutate(.pred_class = as.numeric(.pred_class)) %>%
roc_curve(Survived, .pred_class) %>%
autoplot()
# performance of final model
last_fitted_model %>% collect_metrics()
?update_model
?last_fit
fitBestModel <- function(gridSearchResult, metric, model, formula, data, data_split){
Best_params <- tune::select_best(gridSearchResult[[2]], metric) ## metric 목록 print 되도록
final_spec <- tune::finalize_model(model, Best_params)
final_model <- final_spec %>% fit(eval(parse(text = formula)), data)
last_fitted_model <-
gridSearchResult[[1]] %>%
workflows::update_model(final_spec) %>%
tune::last_fit(data_split)
}
#### finalize model ####
show_best_params <- show_best(regular_res[[2]], n = 1, metric = "roc_auc") # regular_res$.metrics
Best_params <- tune::select_best(regular_res[[2]], metric = "roc_auc") ## metric 목록 print 되도록
tune::select_best(regular_res[[2]], metric = "roc_auc")
?metric
?tune::select_best
data_split
fitBestModel <- function(gridSearchResult = regular_res[[2]],
metric = "roc_auc",
model = model,
formula = formula,
trainingData = data_train,
splitedData = data_split)
fitBestModel <- function(gridSearchResult, metric, model, formula, trainingData, splitedData){
Best_params <- tune::select_best(gridSearchResult[[2]], metric) ## metric 목록 print 되도록
final_spec <- tune::finalize_model(model, Best_params)
final_model <- final_spec %>% fit(eval(parse(text = formula)), data)
last_fitted_model <-
gridSearchResult[[1]] %>%
workflows::update_model(final_spec) %>%
tune::last_fit(data_split)
}
last_fitted_model <- fitBestModel(gridSearchResult = regular_res[[2]],
metric = "roc_auc",
model = model,
formula = formula,
trainingData = data_train,
splitedData = data_split)
last_fitted_model
last_fitted_model$.metrics
fitBestModel <- function(gridSearchResult, metric, model, formula, trainingData){
bestParams <- tune::select_best(gridSearchResult[[2]], metric) ## metric 목록 print 되도록
finalSpec <- tune::finalize_model(model, bestParams)
finalModel <- finalSpec %>% fit(eval(parse(text = formula)), trainingData)
}
last_fitted_model <- fitBestModel(gridSearchResult = regular_res[[2]],
metric = "roc_auc",
model = model,
formula = formula,
trainingData = data_train)
#### finalize model ####
show_best_params <- show_best(regular_res[[2]], n = 1, metric = "roc_auc") # regular_res$.metrics
Best_params <- tune::select_best(regular_res[[2]], metric = "roc_auc") ## metric 목록 print 되도록
final_spec <- tune::finalize_model(model, Best_params)
final_model <- final_spec %>% fit(eval(parse(text = formula)), data_train)
final_model
regular_res[[2]]
last_fitted_model <- fitBestModel(gridSearchResult = regular_res[[2]],
metric = "roc_auc",
model = model,
formula = formula,
trainingData = data_train)
last_fitted_model <- fitBestModel(gridSearchResult = regular_res,
metric = "roc_auc",
model = model,
formula = formula,
trainingData = data_train)
last_fitted_model
?fit
# 함수 추가 시 roxygen 주석을 포함시켜 작성하고, 아래 코드로 주석을 .Rd 파일로 전환 및 NAMESPACE에 추가
devtools::document()
last_fitted_model <- gogphi::fitBestModel(gridSearchResult = regular_res,
metric = "roc_auc",
model = model,
formula = formula,
trainingData = data_train)
last_fitted_model <- goophi::fitBestModel(gridSearchResult = regular_res,
metric = "roc_auc",
model = model,
formula = formula,
trainingData = data_train)
# performance of final model
last_fitted_model %>% collect_metrics()
last_fitted_model
?update_model
?last_fit
# 함수 추가 시 roxygen 주석을 포함시켜 작성하고, 아래 코드로 주석을 .Rd 파일로 전환 및 NAMESPACE에 추가
devtools::document()
final_model <- goophi::fitBestModel(gridSearchResult = regular_res,
metric = "roc_auc",
model = model,
formula = formula,
trainingData = data_train)[[1]]
last_fitted_model <- goophi::fitBestModel(gridSearchResult = regular_res,
metric = "roc_auc",
model = model,
formula = formula,
trainingData = data_train)[[2]]
final_model <- goophi::fitBestModel(gridSearchResult = regular_res,
metric = "roc_auc",
model = model,
formula = formula,
trainingData = data_train,
splitedData = data_split)[[1]]
last_fitted_model <- goophi::fitBestModel(gridSearchResult = regular_res,
metric = "roc_auc",
model = model,
formula = formula,
trainingData = data_train,
splitedData = data_split)[[2]]
# last_fitted_model info
last_fitted_model <-
regular_res[[1]] %>%
update_model(final_spec) %>%
last_fit(data_split)
last_fitted_model <- goophi::fitBestModel(gridSearchResult = regular_res,
metric = "roc_auc",
model = model,
formula = formula,
trainingData = data_train,
splitedData = data_split)[[2]]
# performance of final model
last_fitted_model %>% collect_metrics()
# importance
last_fitted_model %>%
extract_fit_parsnip() %>%
vip()
# performance of final model
last_fitted_model %>% collect_metrics()
